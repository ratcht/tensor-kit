{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alialh/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from load import ModelLoader\n",
    "import torch\n",
    "from transformers import AutoModel, MistralModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alialh/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1365: UserWarning: Current model requires 905976576 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:46<00:00, 23.31s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n",
      "/Users/alialh/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1365: UserWarning: Current model requires 1040195328 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.25s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"Open-Orca/Mistral-7B-OpenOrca\", \"argilla/CapybaraHermes-2.5-Mistral-7B\"]\n",
    "model_weights = [1, 0.5]\n",
    "model_loader = ModelLoader(model_names, model_weights)\n",
    "\n",
    "sum_weights = sum(model_weights)\n",
    "normalized_weights = [weight/sum_weights for weight in model_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_params(model: MistralModel):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `model` is your instantiated Mistral model\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_attn.q_proj.weight    self_attn.q_proj.weight\n",
      "tensor([[ 6.2565e-05,  1.2267e-03, -3.5445e-05,  ...,  4.3996e-03,\n",
      "          2.4100e-05, -6.2227e-04],\n",
      "        [-5.8711e-05, -3.5731e-04,  2.6623e-05,  ..., -2.7831e-04,\n",
      "          3.6756e-06,  3.2393e-04],\n",
      "        [ 1.8378e-05, -5.1943e-04, -1.7087e-06,  ..., -6.0755e-03,\n",
      "         -1.7881e-05, -4.1326e-04],\n",
      "        ...,\n",
      "        [-2.4398e-05, -1.7211e-03, -1.1563e-05,  ...,  4.3511e-04,\n",
      "          7.9473e-06,  3.5254e-04],\n",
      "        [ 7.4903e-06, -1.5564e-03,  1.8358e-05,  ..., -2.0580e-03,\n",
      "         -3.2167e-05,  7.6898e-04],\n",
      "        [ 2.6286e-05,  1.9836e-03,  6.6559e-06,  ..., -2.3548e-04,\n",
      "         -8.0069e-06, -4.9480e-04]], device='mps:0')\n",
      "self_attn.k_proj.weight    self_attn.k_proj.weight\n",
      "tensor([[ 4.3611e-06, -3.3436e-03,  1.3244e-04,  ..., -1.6363e-02,\n",
      "          1.8891e-04, -8.7134e-04],\n",
      "        [ 2.3444e-06,  1.9223e-03, -8.9149e-05,  ...,  7.0178e-03,\n",
      "         -9.7732e-05,  8.3033e-04],\n",
      "        [-1.8497e-05,  3.0518e-03, -6.7612e-05,  ...,  1.7949e-02,\n",
      "         -1.0967e-04,  6.2084e-04],\n",
      "        ...,\n",
      "        [-2.5376e-04,  1.9089e-03, -4.1660e-04,  ...,  2.1515e-03,\n",
      "          3.6685e-04, -2.6743e-04],\n",
      "        [-1.7985e-04, -4.3755e-03, -2.5670e-04,  ...,  6.0908e-04,\n",
      "          5.3946e-04, -2.3053e-03],\n",
      "        [ 2.5558e-04, -1.7643e-03,  4.4322e-04,  ..., -1.8915e-03,\n",
      "         -4.0102e-04,  8.8692e-04]], device='mps:0')\n",
      "self_attn.v_proj.weight    self_attn.v_proj.weight\n",
      "tensor([[-4.2645e-04, -1.7045e-03, -6.6328e-04,  ...,  4.9515e-03,\n",
      "         -8.8414e-06,  2.1273e-03],\n",
      "        [-5.1928e-04,  5.0621e-03, -3.7972e-04,  ...,  4.4670e-03,\n",
      "         -7.3973e-04, -6.9141e-04],\n",
      "        [ 2.7243e-04,  2.0638e-03, -5.9891e-04,  ..., -6.5422e-04,\n",
      "         -1.0516e-04, -5.5542e-03],\n",
      "        ...,\n",
      "        [ 6.1591e-04,  2.1566e-03, -2.9453e-04,  ...,  3.5343e-03,\n",
      "         -1.7783e-03, -2.2812e-03],\n",
      "        [-3.5461e-04, -4.7417e-03, -4.2621e-04,  ...,  2.7625e-03,\n",
      "          7.0508e-04, -5.5393e-04],\n",
      "        [-6.2911e-04, -2.7777e-03,  5.1355e-04,  ..., -3.8242e-04,\n",
      "          6.1289e-04,  1.4544e-03]], device='mps:0')\n",
      "self_attn.o_proj.weight    self_attn.o_proj.weight\n",
      "tensor([[ 6.3149e-04,  4.4975e-03,  4.2547e-03,  ..., -1.0239e-03,\n",
      "         -2.8340e-04,  2.6449e-04],\n",
      "        [ 1.7832e-04, -2.5965e-03, -7.0238e-04,  ...,  8.0872e-04,\n",
      "         -1.1338e-03, -9.9532e-04],\n",
      "        [-2.0237e-03,  2.0320e-03, -3.0398e-06,  ...,  1.1746e-03,\n",
      "          3.3779e-03, -3.0403e-03],\n",
      "        ...,\n",
      "        [ 4.0080e-03, -1.3288e-03,  2.0542e-03,  ..., -3.3175e-03,\n",
      "          1.3965e-03,  5.2020e-03],\n",
      "        [ 2.8687e-03, -3.8166e-03, -2.1756e-03,  ..., -2.3099e-04,\n",
      "         -2.7269e-03, -2.8378e-04],\n",
      "        [ 4.5280e-03, -2.9583e-03, -2.3384e-03,  ...,  4.8542e-04,\n",
      "          1.6371e-03, -5.7268e-04]], device='mps:0')\n",
      "mlp.gate_proj.weight    mlp.gate_proj.weight\n",
      "tensor([[-4.2661e-03, -1.0653e-03, -1.4159e-03,  ...,  2.6588e-03,\n",
      "          3.4962e-03,  3.1357e-03],\n",
      "        [ 3.5350e-03, -5.6362e-04,  6.1989e-04,  ...,  4.0658e-04,\n",
      "          3.2094e-03,  1.1387e-03],\n",
      "        [-6.9141e-04,  1.6187e-03,  1.5386e-03,  ..., -3.0181e-03,\n",
      "         -1.7643e-03, -1.3275e-03],\n",
      "        ...,\n",
      "        [ 2.0065e-03, -5.9700e-04, -2.2647e-03,  ...,  1.8658e-04,\n",
      "         -3.1102e-03,  9.1426e-04],\n",
      "        [ 2.4325e-03, -4.2852e-03, -4.7048e-04,  ...,  2.7617e-06,\n",
      "          3.7177e-04,  4.2903e-03],\n",
      "        [ 2.9202e-03,  7.4387e-04,  4.4835e-03,  ...,  1.5558e-03,\n",
      "         -2.1203e-03, -3.7352e-03]], device='mps:0')\n",
      "mlp.up_proj.weight    mlp.up_proj.weight\n",
      "tensor([[-2.1863e-04, -1.0856e-04, -8.5433e-04,  ...,  5.6165e-03,\n",
      "          3.6488e-03,  3.7678e-04],\n",
      "        [-4.1313e-03, -1.1854e-03, -1.6912e-03,  ...,  2.1121e-03,\n",
      "          1.9226e-03, -1.4663e-04],\n",
      "        [-3.0549e-04,  1.7360e-03, -1.5710e-03,  ...,  1.4893e-03,\n",
      "         -6.4309e-04, -5.4741e-04],\n",
      "        ...,\n",
      "        [-2.8642e-03, -1.4989e-03,  1.6228e-03,  ..., -3.6564e-03,\n",
      "         -2.7663e-03,  4.3615e-03],\n",
      "        [ 2.7046e-03, -2.7479e-03, -5.8543e-03,  ...,  2.6258e-04,\n",
      "         -6.5956e-03,  3.9202e-03],\n",
      "        [-1.5310e-03, -1.6448e-03,  2.3119e-04,  ...,  1.4187e-03,\n",
      "         -5.5656e-03,  4.9909e-05]], device='mps:0')\n",
      "mlp.down_proj.weight    mlp.down_proj.weight\n",
      "tensor([[-0.0027,  0.0003, -0.0005,  ..., -0.0016,  0.0037, -0.0008],\n",
      "        [ 0.0013, -0.0049,  0.0025,  ..., -0.0016,  0.0015, -0.0038],\n",
      "        [ 0.0055, -0.0081,  0.0023,  ...,  0.0030, -0.0051,  0.0041],\n",
      "        ...,\n",
      "        [ 0.0056,  0.0023, -0.0013,  ..., -0.0011,  0.0055, -0.0014],\n",
      "        [-0.0025,  0.0025, -0.0019,  ...,  0.0008,  0.0001,  0.0017],\n",
      "        [-0.0027, -0.0054, -0.0007,  ..., -0.0045,  0.0008, -0.0020]],\n",
      "       device='mps:0')\n",
      "input_layernorm.weight    input_layernorm.weight\n",
      "tensor([ 4.0372e-05, -1.2085e-02,  1.1015e-04,  ...,  3.5400e-02,\n",
      "        -1.9455e-04,  6.5104e-03], device='mps:0')\n",
      "post_attention_layernorm.weight    post_attention_layernorm.weight\n",
      "tensor([0.4167, 0.4121, 0.3945,  ..., 0.4199, 0.3971, 0.4004], device='mps:0')\n",
      "\n",
      "\n",
      "self_attn.q_proj.weight    self_attn.q_proj.weight\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor on device meta is not on the expected device mps:0!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# param_1 = param_1.to(device)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# param_2 = param_2.to(device)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m tensors \u001b[38;5;241m=\u001b[39m [param_1\u001b[38;5;241m.\u001b[39mdata, param_2\u001b[38;5;241m.\u001b[39mdata]\n\u001b[0;32m---> 12\u001b[0m tensors \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(normalized_weights, dtype\u001b[38;5;241m=\u001b[39mtensors\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensors\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(weights\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tensors\u001b[38;5;241m.\u001b[39mshape):\n",
      "File \u001b[0;32m~/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:252\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, is_out\u001b[38;5;241m=\u001b[39m(out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_names)\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3847\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(tensors, dim)\u001b[0m\n\u001b[1;32m   3845\u001b[0m     result_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   3846\u001b[0m     result_sizes\u001b[38;5;241m.\u001b[39minsert(wrapped_dim, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m-> 3847\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mview(result_sizes)\n\u001b[1;32m   3850\u001b[0m \u001b[38;5;66;03m# If dim == tensors[0].ndim, view cannot efficiently handle it\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:252\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, is_out\u001b[38;5;241m=\u001b[39m(out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_names)\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:137\u001b[0m, in \u001b[0;36melementwise_type_promotion_wrapper.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m promoted_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    131\u001b[0m     x: _maybe_convert_to_dtype(bound\u001b[38;5;241m.\u001b[39marguments[x], compute_dtype)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_promoting_arg_names  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    134\u001b[0m }\n\u001b[1;32m    135\u001b[0m bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mupdate(promoted_args)\n\u001b[0;32m--> 137\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Override the return_dtype if a dtype arg is present and not None\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m bound\u001b[38;5;241m.\u001b[39marguments:\n",
      "File \u001b[0;32m~/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2719\u001b[0m, in \u001b[0;36mcat\u001b[0;34m(tensors, dim)\u001b[0m\n\u001b[1;32m   2716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors:\n\u001b[1;32m   2717\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, TensorLike)\n\u001b[0;32m-> 2719\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_same_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_cpu_scalar_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m guard_size_oblivious\n\u001b[1;32m   2723\u001b[0m \u001b[38;5;66;03m# This is a bit tricky.  Naively, you would expect to just pick one\u001b[39;00m\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;66;03m# arbitrary tensor and check that all tensors match this tensor.  However,\u001b[39;00m\n\u001b[1;32m   2725\u001b[0m \u001b[38;5;66;03m# there is legacy behavior which says that if you have a 1-D empty tensor\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m \u001b[38;5;66;03m# but we do it slightly different here for better handling for unbacked\u001b[39;00m\n\u001b[1;32m   2737\u001b[0m \u001b[38;5;66;03m# SymInts\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AI Research/Merging/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:740\u001b[0m, in \u001b[0;36mcheck_same_device\u001b[0;34m(allow_cpu_scalar_tensors, *args)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m!=\u001b[39m arg\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[1;32m    733\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor on device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(arg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m         )\n\u001b[0;32m--> 740\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected type when checking for same device, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(arg)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    744\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor on device meta is not on the expected device mps:0!"
     ]
    }
   ],
   "source": [
    "for layer_1, layer_2 in zip(*[model.layers for model in model_loader.models]):\n",
    "  for n_1, n_2 in zip(layer_1.named_parameters(), layer_2.named_parameters()):\n",
    "    name_1, param_1 = n_1\n",
    "    name_2, param_2 = n_2\n",
    "\n",
    "    print(name_1, \"  \", name_2)\n",
    "\n",
    "    # param_1 = param_1.to(device)\n",
    "    # param_2 = param_2.to(device)\n",
    "\n",
    "    tensors = [param_1.data, param_2.data]\n",
    "    tensors = torch.stack(tensors, dim=0)\n",
    "    weights = torch.tensor(normalized_weights, dtype=tensors.dtype, device=tensors.device)\n",
    "\n",
    "    while len(weights.shape) < len(tensors.shape):\n",
    "      weights.unsqueeze_(-1)\n",
    "\n",
    "    res = (weights * tensors).sum(dim=0)\n",
    "    # res = normalized_weights[0]*param_1.data + normalized_weights[1]*param_2.data\n",
    "\n",
    "    print(res)\n",
    "\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model_loader.models[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model_loader.models[0].named_modules():\n",
    "  print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_1, t_2 in zip(*[model.named_parameters() for model in model_loader.models]):\n",
    "  name_1, param_1 = t_1\n",
    "  name_2, param_2 = t_2\n",
    "  print(f\"Layer1: {name_1} | Size1: {param_1.size()}\")\n",
    "  print(f\"Layer2: {name_2} | Size2: {param_2.size()}\")\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_layers(model_loader.models[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
